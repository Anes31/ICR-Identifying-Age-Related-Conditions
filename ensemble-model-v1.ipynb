{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pycaret\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, KFold, RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# from pycaret.classification import setup, evaluate_model, compare_models, plot_model, add_metric\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "greeks = pd.read_csv('greeks.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_0 = train.drop(['Id', 'Class'], axis=1).copy()\n",
    "y = train.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>BN</th>\n",
       "      <th>BP</th>\n",
       "      <th>BQ</th>\n",
       "      <th>BR</th>\n",
       "      <th>BZ</th>\n",
       "      <th>CB</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>CF</th>\n",
       "      <th>CH</th>\n",
       "      <th>CL</th>\n",
       "      <th>CR</th>\n",
       "      <th>CS</th>\n",
       "      <th>CU</th>\n",
       "      <th>CW</th>\n",
       "      <th>DA</th>\n",
       "      <th>DE</th>\n",
       "      <th>DF</th>\n",
       "      <th>DH</th>\n",
       "      <th>DI</th>\n",
       "      <th>DL</th>\n",
       "      <th>DN</th>\n",
       "      <th>DU</th>\n",
       "      <th>DV</th>\n",
       "      <th>DY</th>\n",
       "      <th>EB</th>\n",
       "      <th>EE</th>\n",
       "      <th>EG</th>\n",
       "      <th>EH</th>\n",
       "      <th>EJ</th>\n",
       "      <th>EL</th>\n",
       "      <th>EP</th>\n",
       "      <th>EU</th>\n",
       "      <th>FC</th>\n",
       "      <th>FD</th>\n",
       "      <th>FE</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.209377</td>\n",
       "      <td>3109.03329</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>22.394407</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>9.812214</td>\n",
       "      <td>5.555634</td>\n",
       "      <td>4126.58731</td>\n",
       "      <td>22.5984</td>\n",
       "      <td>175.638726</td>\n",
       "      <td>152.707705</td>\n",
       "      <td>823.928241</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>47.223358</td>\n",
       "      <td>0.563481</td>\n",
       "      <td>23.387600</td>\n",
       "      <td>4.851915</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.069225</td>\n",
       "      <td>13.784111</td>\n",
       "      <td>1.302012</td>\n",
       "      <td>36.205956</td>\n",
       "      <td>69.08340</td>\n",
       "      <td>295.570575</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.284232</td>\n",
       "      <td>89.245560</td>\n",
       "      <td>84.31664</td>\n",
       "      <td>29.657104</td>\n",
       "      <td>5.310690</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>23.187704</td>\n",
       "      <td>7.294176</td>\n",
       "      <td>1.987283</td>\n",
       "      <td>1433.166750</td>\n",
       "      <td>0.949104</td>\n",
       "      <td>B</td>\n",
       "      <td>30.879420</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>3.828384</td>\n",
       "      <td>13.394640</td>\n",
       "      <td>10.265073</td>\n",
       "      <td>9028.291921</td>\n",
       "      <td>3.583450</td>\n",
       "      <td>7.298162</td>\n",
       "      <td>1.73855</td>\n",
       "      <td>0.094822</td>\n",
       "      <td>11.339138</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2003.810319</td>\n",
       "      <td>22.136229</td>\n",
       "      <td>69.834944</td>\n",
       "      <td>0.120343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.145282</td>\n",
       "      <td>978.76416</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>36.968889</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.632190</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>13.517790</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5496.92824</td>\n",
       "      <td>19.4205</td>\n",
       "      <td>155.868030</td>\n",
       "      <td>14.754720</td>\n",
       "      <td>51.216883</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>30.284345</td>\n",
       "      <td>0.484710</td>\n",
       "      <td>50.628208</td>\n",
       "      <td>6.085041</td>\n",
       "      <td>0.031442</td>\n",
       "      <td>1.113875</td>\n",
       "      <td>1.117800</td>\n",
       "      <td>28.310953</td>\n",
       "      <td>1.357182</td>\n",
       "      <td>37.476568</td>\n",
       "      <td>70.79836</td>\n",
       "      <td>178.553100</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.363489</td>\n",
       "      <td>110.581815</td>\n",
       "      <td>75.74548</td>\n",
       "      <td>37.532000</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>17.222328</td>\n",
       "      <td>4.926396</td>\n",
       "      <td>0.858603</td>\n",
       "      <td>1111.287150</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>A</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>95.415086</td>\n",
       "      <td>52.260480</td>\n",
       "      <td>17.175984</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>6785.003474</td>\n",
       "      <td>10.358927</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.568932</td>\n",
       "      <td>9.292698</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>27981.562750</td>\n",
       "      <td>29.135430</td>\n",
       "      <td>32.131996</td>\n",
       "      <td>21.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470030</td>\n",
       "      <td>2635.10654</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>32.360553</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.732840</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>12.824570</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>5135.78024</td>\n",
       "      <td>26.4825</td>\n",
       "      <td>128.988531</td>\n",
       "      <td>219.320160</td>\n",
       "      <td>482.141594</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>32.563713</td>\n",
       "      <td>0.495852</td>\n",
       "      <td>85.955376</td>\n",
       "      <td>5.376488</td>\n",
       "      <td>0.036218</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.700350</td>\n",
       "      <td>39.364743</td>\n",
       "      <td>1.009611</td>\n",
       "      <td>21.459644</td>\n",
       "      <td>70.81970</td>\n",
       "      <td>321.426625</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.210441</td>\n",
       "      <td>120.056438</td>\n",
       "      <td>65.46984</td>\n",
       "      <td>28.053464</td>\n",
       "      <td>1.289739</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>36.861352</td>\n",
       "      <td>7.813674</td>\n",
       "      <td>8.146651</td>\n",
       "      <td>1494.076488</td>\n",
       "      <td>0.377208</td>\n",
       "      <td>B</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>5.390628</td>\n",
       "      <td>224.207424</td>\n",
       "      <td>8.745201</td>\n",
       "      <td>8338.906181</td>\n",
       "      <td>11.626917</td>\n",
       "      <td>7.709560</td>\n",
       "      <td>0.97556</td>\n",
       "      <td>1.198821</td>\n",
       "      <td>37.077772</td>\n",
       "      <td>88.609437</td>\n",
       "      <td>13676.957810</td>\n",
       "      <td>28.022851</td>\n",
       "      <td>35.192676</td>\n",
       "      <td>0.196941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.252107</td>\n",
       "      <td>3819.65177</td>\n",
       "      <td>120.201618</td>\n",
       "      <td>77.112203</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.685344</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>11.053708</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4169.67738</td>\n",
       "      <td>23.6577</td>\n",
       "      <td>237.282264</td>\n",
       "      <td>11.050410</td>\n",
       "      <td>661.518640</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>15.201914</td>\n",
       "      <td>0.717882</td>\n",
       "      <td>88.159360</td>\n",
       "      <td>2.347652</td>\n",
       "      <td>0.029054</td>\n",
       "      <td>1.400300</td>\n",
       "      <td>0.636075</td>\n",
       "      <td>41.116960</td>\n",
       "      <td>0.722727</td>\n",
       "      <td>21.530392</td>\n",
       "      <td>47.27586</td>\n",
       "      <td>196.607985</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.292431</td>\n",
       "      <td>139.824570</td>\n",
       "      <td>71.57120</td>\n",
       "      <td>24.354856</td>\n",
       "      <td>2.655345</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>52.003884</td>\n",
       "      <td>7.386060</td>\n",
       "      <td>3.813326</td>\n",
       "      <td>15691.552180</td>\n",
       "      <td>0.614484</td>\n",
       "      <td>B</td>\n",
       "      <td>31.674357</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>31.323372</td>\n",
       "      <td>59.301984</td>\n",
       "      <td>7.884336</td>\n",
       "      <td>10965.766040</td>\n",
       "      <td>14.852022</td>\n",
       "      <td>6.122162</td>\n",
       "      <td>0.49706</td>\n",
       "      <td>0.284466</td>\n",
       "      <td>18.529584</td>\n",
       "      <td>82.416803</td>\n",
       "      <td>2094.262452</td>\n",
       "      <td>39.948656</td>\n",
       "      <td>90.493248</td>\n",
       "      <td>0.155829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.380297</td>\n",
       "      <td>3733.04844</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>14.103738</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>3.942255</td>\n",
       "      <td>0.054810</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>102.151980</td>\n",
       "      <td>5728.73412</td>\n",
       "      <td>24.0108</td>\n",
       "      <td>324.546318</td>\n",
       "      <td>149.717165</td>\n",
       "      <td>6074.859475</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>82.213495</td>\n",
       "      <td>0.536467</td>\n",
       "      <td>72.644264</td>\n",
       "      <td>30.537722</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.693150</td>\n",
       "      <td>31.724726</td>\n",
       "      <td>0.827550</td>\n",
       "      <td>34.415360</td>\n",
       "      <td>74.06532</td>\n",
       "      <td>200.178160</td>\n",
       "      <td>0.23868</td>\n",
       "      <td>0.207708</td>\n",
       "      <td>97.920120</td>\n",
       "      <td>52.83888</td>\n",
       "      <td>26.019912</td>\n",
       "      <td>1.144902</td>\n",
       "      <td>1.74307</td>\n",
       "      <td>9.064856</td>\n",
       "      <td>7.350720</td>\n",
       "      <td>3.490846</td>\n",
       "      <td>1403.656300</td>\n",
       "      <td>0.164268</td>\n",
       "      <td>B</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>91.994825</td>\n",
       "      <td>51.141336</td>\n",
       "      <td>29.102640</td>\n",
       "      <td>4.274640</td>\n",
       "      <td>16198.049590</td>\n",
       "      <td>13.666727</td>\n",
       "      <td>8.153058</td>\n",
       "      <td>48.50134</td>\n",
       "      <td>0.121914</td>\n",
       "      <td>16.408728</td>\n",
       "      <td>146.109943</td>\n",
       "      <td>8524.370502</td>\n",
       "      <td>45.381316</td>\n",
       "      <td>36.262628</td>\n",
       "      <td>0.096614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AB          AF          AH         AM        AR        AX        AY  \\\n",
       "0  0.209377  3109.03329   85.200147  22.394407  8.138688  0.699861  0.025578   \n",
       "1  0.145282   978.76416   85.200147  36.968889  8.138688  3.632190  0.025578   \n",
       "2  0.470030  2635.10654   85.200147  32.360553  8.138688  6.732840  0.025578   \n",
       "3  0.252107  3819.65177  120.201618  77.112203  8.138688  3.685344  0.025578   \n",
       "4  0.380297  3733.04844   85.200147  14.103738  8.138688  3.942255  0.054810   \n",
       "\n",
       "          AZ          BC         BD        BN          BP          BQ  \\\n",
       "0   9.812214    5.555634  4126.58731  22.5984  175.638726  152.707705   \n",
       "1  13.517790    1.229900  5496.92824  19.4205  155.868030   14.754720   \n",
       "2  12.824570    1.229900  5135.78024  26.4825  128.988531  219.320160   \n",
       "3  11.053708    1.229900  4169.67738  23.6577  237.282264   11.050410   \n",
       "4   3.396778  102.151980  5728.73412  24.0108  324.546318  149.717165   \n",
       "\n",
       "            BR          BZ         CB        CC        CD          CF  \\\n",
       "0   823.928241  257.432377  47.223358  0.563481  23.387600   4.851915   \n",
       "1    51.216883  257.432377  30.284345  0.484710  50.628208   6.085041   \n",
       "2   482.141594  257.432377  32.563713  0.495852  85.955376   5.376488   \n",
       "3   661.518640  257.432377  15.201914  0.717882  88.159360   2.347652   \n",
       "4  6074.859475  257.432377  82.213495  0.536467  72.644264  30.537722   \n",
       "\n",
       "         CH        CL        CR         CS        CU        CW         DA  \\\n",
       "0  0.023482  1.050225  0.069225  13.784111  1.302012  36.205956  69.08340   \n",
       "1  0.031442  1.113875  1.117800  28.310953  1.357182  37.476568  70.79836   \n",
       "2  0.036218  1.050225  0.700350  39.364743  1.009611  21.459644  70.81970   \n",
       "3  0.029054  1.400300  0.636075  41.116960  0.722727  21.530392  47.27586   \n",
       "4  0.025472  1.050225  0.693150  31.724726  0.827550  34.415360  74.06532   \n",
       "\n",
       "           DE       DF        DH          DI        DL         DN        DU  \\\n",
       "0  295.570575  0.23868  0.284232   89.245560  84.31664  29.657104  5.310690   \n",
       "1  178.553100  0.23868  0.363489  110.581815  75.74548  37.532000  0.005518   \n",
       "2  321.426625  0.23868  0.210441  120.056438  65.46984  28.053464  1.289739   \n",
       "3  196.607985  0.23868  0.292431  139.824570  71.57120  24.354856  2.655345   \n",
       "4  200.178160  0.23868  0.207708   97.920120  52.83888  26.019912  1.144902   \n",
       "\n",
       "        DV         DY        EB        EE            EG        EH EJ  \\\n",
       "0  1.74307  23.187704  7.294176  1.987283   1433.166750  0.949104  B   \n",
       "1  1.74307  17.222328  4.926396  0.858603   1111.287150  0.003042  A   \n",
       "2  1.74307  36.861352  7.813674  8.146651   1494.076488  0.377208  B   \n",
       "3  1.74307  52.003884  7.386060  3.813326  15691.552180  0.614484  B   \n",
       "4  1.74307   9.064856  7.350720  3.490846   1403.656300  0.164268  B   \n",
       "\n",
       "           EL         EP         EU          FC        FD             FE  \\\n",
       "0   30.879420  78.526968   3.828384   13.394640  10.265073   9028.291921   \n",
       "1  109.125159  95.415086  52.260480   17.175984   0.296850   6785.003474   \n",
       "2  109.125159  78.526968   5.390628  224.207424   8.745201   8338.906181   \n",
       "3   31.674357  78.526968  31.323372   59.301984   7.884336  10965.766040   \n",
       "4  109.125159  91.994825  51.141336   29.102640   4.274640  16198.049590   \n",
       "\n",
       "          FI        FL        FR        FS         GB          GE  \\\n",
       "0   3.583450  7.298162   1.73855  0.094822  11.339138   72.611063   \n",
       "1  10.358927  0.173229   0.49706  0.568932   9.292698   72.611063   \n",
       "2  11.626917  7.709560   0.97556  1.198821  37.077772   88.609437   \n",
       "3  14.852022  6.122162   0.49706  0.284466  18.529584   82.416803   \n",
       "4  13.666727  8.153058  48.50134  0.121914  16.408728  146.109943   \n",
       "\n",
       "             GF         GH         GI         GL  \n",
       "0   2003.810319  22.136229  69.834944   0.120343  \n",
       "1  27981.562750  29.135430  32.131996  21.978000  \n",
       "2  13676.957810  28.022851  35.192676   0.196941  \n",
       "3   2094.262452  39.948656  90.493248   0.155829  \n",
       "4   8524.370502  45.381316  36.262628   0.096614  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AB</th>\n",
       "      <th>AF</th>\n",
       "      <th>AH</th>\n",
       "      <th>AM</th>\n",
       "      <th>AR</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>BC</th>\n",
       "      <th>BD</th>\n",
       "      <th>BN</th>\n",
       "      <th>BP</th>\n",
       "      <th>BQ</th>\n",
       "      <th>BR</th>\n",
       "      <th>BZ</th>\n",
       "      <th>CB</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>CF</th>\n",
       "      <th>CH</th>\n",
       "      <th>CL</th>\n",
       "      <th>CR</th>\n",
       "      <th>CS</th>\n",
       "      <th>CU</th>\n",
       "      <th>CW</th>\n",
       "      <th>DA</th>\n",
       "      <th>DE</th>\n",
       "      <th>DF</th>\n",
       "      <th>DH</th>\n",
       "      <th>DI</th>\n",
       "      <th>DL</th>\n",
       "      <th>DN</th>\n",
       "      <th>DU</th>\n",
       "      <th>DV</th>\n",
       "      <th>DY</th>\n",
       "      <th>EB</th>\n",
       "      <th>EE</th>\n",
       "      <th>EG</th>\n",
       "      <th>EH</th>\n",
       "      <th>EL</th>\n",
       "      <th>EP</th>\n",
       "      <th>EU</th>\n",
       "      <th>FC</th>\n",
       "      <th>FD</th>\n",
       "      <th>FE</th>\n",
       "      <th>FI</th>\n",
       "      <th>FL</th>\n",
       "      <th>FR</th>\n",
       "      <th>FS</th>\n",
       "      <th>GB</th>\n",
       "      <th>GE</th>\n",
       "      <th>GF</th>\n",
       "      <th>GH</th>\n",
       "      <th>GI</th>\n",
       "      <th>GL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>615.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>616.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.477149</td>\n",
       "      <td>3502.013221</td>\n",
       "      <td>118.624513</td>\n",
       "      <td>38.968552</td>\n",
       "      <td>10.128242</td>\n",
       "      <td>5.545576</td>\n",
       "      <td>0.060320</td>\n",
       "      <td>10.566447</td>\n",
       "      <td>8.053012</td>\n",
       "      <td>5350.388655</td>\n",
       "      <td>21.419492</td>\n",
       "      <td>231.322223</td>\n",
       "      <td>98.328737</td>\n",
       "      <td>1218.133238</td>\n",
       "      <td>550.632525</td>\n",
       "      <td>77.104151</td>\n",
       "      <td>0.688801</td>\n",
       "      <td>90.251735</td>\n",
       "      <td>11.241064</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>1.403761</td>\n",
       "      <td>0.742262</td>\n",
       "      <td>36.917590</td>\n",
       "      <td>1.383792</td>\n",
       "      <td>27.165653</td>\n",
       "      <td>51.128326</td>\n",
       "      <td>401.901299</td>\n",
       "      <td>0.633884</td>\n",
       "      <td>0.367002</td>\n",
       "      <td>146.972099</td>\n",
       "      <td>94.795377</td>\n",
       "      <td>26.370568</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>1.924830</td>\n",
       "      <td>26.388989</td>\n",
       "      <td>9.072700</td>\n",
       "      <td>3.064778</td>\n",
       "      <td>1731.248215</td>\n",
       "      <td>0.305107</td>\n",
       "      <td>69.582596</td>\n",
       "      <td>105.060712</td>\n",
       "      <td>69.117005</td>\n",
       "      <td>71.341526</td>\n",
       "      <td>6.930086</td>\n",
       "      <td>10306.810737</td>\n",
       "      <td>10.111079</td>\n",
       "      <td>5.433199</td>\n",
       "      <td>3.533905</td>\n",
       "      <td>0.421501</td>\n",
       "      <td>20.724856</td>\n",
       "      <td>131.714987</td>\n",
       "      <td>14679.595398</td>\n",
       "      <td>31.489716</td>\n",
       "      <td>50.584437</td>\n",
       "      <td>8.530961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468388</td>\n",
       "      <td>2300.322717</td>\n",
       "      <td>127.838950</td>\n",
       "      <td>69.728226</td>\n",
       "      <td>10.518877</td>\n",
       "      <td>2.551696</td>\n",
       "      <td>0.416817</td>\n",
       "      <td>4.350645</td>\n",
       "      <td>65.166943</td>\n",
       "      <td>3021.326641</td>\n",
       "      <td>3.478278</td>\n",
       "      <td>183.992505</td>\n",
       "      <td>96.479371</td>\n",
       "      <td>7575.293707</td>\n",
       "      <td>2076.371275</td>\n",
       "      <td>159.049302</td>\n",
       "      <td>0.263994</td>\n",
       "      <td>51.585130</td>\n",
       "      <td>13.571133</td>\n",
       "      <td>0.014808</td>\n",
       "      <td>1.922210</td>\n",
       "      <td>0.281195</td>\n",
       "      <td>17.266347</td>\n",
       "      <td>0.538717</td>\n",
       "      <td>14.645993</td>\n",
       "      <td>21.210888</td>\n",
       "      <td>317.745623</td>\n",
       "      <td>1.912384</td>\n",
       "      <td>0.112989</td>\n",
       "      <td>86.084419</td>\n",
       "      <td>28.243187</td>\n",
       "      <td>8.038825</td>\n",
       "      <td>9.034721</td>\n",
       "      <td>1.484555</td>\n",
       "      <td>18.116679</td>\n",
       "      <td>6.200281</td>\n",
       "      <td>2.058344</td>\n",
       "      <td>1790.227476</td>\n",
       "      <td>1.847499</td>\n",
       "      <td>38.555707</td>\n",
       "      <td>68.445620</td>\n",
       "      <td>390.187057</td>\n",
       "      <td>165.551545</td>\n",
       "      <td>64.754262</td>\n",
       "      <td>11331.294051</td>\n",
       "      <td>2.934025</td>\n",
       "      <td>11.496257</td>\n",
       "      <td>50.181948</td>\n",
       "      <td>1.305365</td>\n",
       "      <td>9.991907</td>\n",
       "      <td>144.181524</td>\n",
       "      <td>19352.959387</td>\n",
       "      <td>9.864239</td>\n",
       "      <td>36.266251</td>\n",
       "      <td>10.327010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.081187</td>\n",
       "      <td>192.593280</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>3.177522</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>0.699861</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>3.396778</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>1693.624320</td>\n",
       "      <td>9.886800</td>\n",
       "      <td>72.948951</td>\n",
       "      <td>1.331155</td>\n",
       "      <td>51.216883</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>12.499760</td>\n",
       "      <td>0.176874</td>\n",
       "      <td>23.387600</td>\n",
       "      <td>0.510888</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.069225</td>\n",
       "      <td>13.784111</td>\n",
       "      <td>0.137925</td>\n",
       "      <td>7.030640</td>\n",
       "      <td>6.906400</td>\n",
       "      <td>35.998895</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.040995</td>\n",
       "      <td>60.232470</td>\n",
       "      <td>10.345600</td>\n",
       "      <td>6.339496</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.743070</td>\n",
       "      <td>0.804068</td>\n",
       "      <td>4.926396</td>\n",
       "      <td>0.286201</td>\n",
       "      <td>185.594100</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>5.394675</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>3.828384</td>\n",
       "      <td>7.534128</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>1563.136688</td>\n",
       "      <td>3.583450</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>4.102182</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>13.038894</td>\n",
       "      <td>9.432735</td>\n",
       "      <td>0.897628</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.252107</td>\n",
       "      <td>2197.345480</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>12.270314</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>4.128294</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>8.129580</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4155.702870</td>\n",
       "      <td>19.420500</td>\n",
       "      <td>156.847239</td>\n",
       "      <td>27.834425</td>\n",
       "      <td>424.990642</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>23.317567</td>\n",
       "      <td>0.563688</td>\n",
       "      <td>64.724192</td>\n",
       "      <td>5.066306</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.589575</td>\n",
       "      <td>29.782467</td>\n",
       "      <td>1.070298</td>\n",
       "      <td>7.030640</td>\n",
       "      <td>37.942520</td>\n",
       "      <td>188.815690</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.295164</td>\n",
       "      <td>102.703553</td>\n",
       "      <td>78.232240</td>\n",
       "      <td>20.888264</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>1.743070</td>\n",
       "      <td>14.715792</td>\n",
       "      <td>5.965392</td>\n",
       "      <td>1.648679</td>\n",
       "      <td>1111.160625</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>30.927468</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>4.324656</td>\n",
       "      <td>25.815384</td>\n",
       "      <td>0.296850</td>\n",
       "      <td>5164.666260</td>\n",
       "      <td>8.523098</td>\n",
       "      <td>0.173229</td>\n",
       "      <td>0.497060</td>\n",
       "      <td>0.067730</td>\n",
       "      <td>14.036718</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>2798.992584</td>\n",
       "      <td>25.034888</td>\n",
       "      <td>23.011684</td>\n",
       "      <td>0.124392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.354659</td>\n",
       "      <td>3120.318960</td>\n",
       "      <td>85.200147</td>\n",
       "      <td>20.533110</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>5.031912</td>\n",
       "      <td>0.025578</td>\n",
       "      <td>10.461320</td>\n",
       "      <td>1.229900</td>\n",
       "      <td>4997.960730</td>\n",
       "      <td>21.186000</td>\n",
       "      <td>193.908816</td>\n",
       "      <td>61.642115</td>\n",
       "      <td>627.417402</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>42.554330</td>\n",
       "      <td>0.658715</td>\n",
       "      <td>79.819104</td>\n",
       "      <td>9.123000</td>\n",
       "      <td>0.027860</td>\n",
       "      <td>1.050225</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>34.835130</td>\n",
       "      <td>1.351665</td>\n",
       "      <td>36.019104</td>\n",
       "      <td>49.180940</td>\n",
       "      <td>307.509595</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.358023</td>\n",
       "      <td>130.050630</td>\n",
       "      <td>96.264960</td>\n",
       "      <td>25.248800</td>\n",
       "      <td>0.251741</td>\n",
       "      <td>1.743070</td>\n",
       "      <td>21.642456</td>\n",
       "      <td>8.149404</td>\n",
       "      <td>2.616119</td>\n",
       "      <td>1493.817413</td>\n",
       "      <td>0.085176</td>\n",
       "      <td>71.949306</td>\n",
       "      <td>78.526968</td>\n",
       "      <td>22.641144</td>\n",
       "      <td>36.394008</td>\n",
       "      <td>1.870155</td>\n",
       "      <td>7345.143424</td>\n",
       "      <td>9.945452</td>\n",
       "      <td>3.028141</td>\n",
       "      <td>1.131000</td>\n",
       "      <td>0.250601</td>\n",
       "      <td>18.771436</td>\n",
       "      <td>72.611063</td>\n",
       "      <td>7838.273610</td>\n",
       "      <td>30.608946</td>\n",
       "      <td>41.007968</td>\n",
       "      <td>0.337827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.559763</td>\n",
       "      <td>4361.637390</td>\n",
       "      <td>113.739540</td>\n",
       "      <td>39.139886</td>\n",
       "      <td>8.138688</td>\n",
       "      <td>6.431634</td>\n",
       "      <td>0.036845</td>\n",
       "      <td>12.969516</td>\n",
       "      <td>5.081244</td>\n",
       "      <td>6035.885700</td>\n",
       "      <td>23.657700</td>\n",
       "      <td>247.803462</td>\n",
       "      <td>134.009015</td>\n",
       "      <td>975.649259</td>\n",
       "      <td>257.432377</td>\n",
       "      <td>77.310097</td>\n",
       "      <td>0.772206</td>\n",
       "      <td>99.813520</td>\n",
       "      <td>13.565901</td>\n",
       "      <td>0.034427</td>\n",
       "      <td>1.228445</td>\n",
       "      <td>0.859350</td>\n",
       "      <td>40.529401</td>\n",
       "      <td>1.660617</td>\n",
       "      <td>37.935832</td>\n",
       "      <td>61.408760</td>\n",
       "      <td>507.896200</td>\n",
       "      <td>0.238680</td>\n",
       "      <td>0.426348</td>\n",
       "      <td>165.836955</td>\n",
       "      <td>110.640680</td>\n",
       "      <td>30.544224</td>\n",
       "      <td>1.058690</td>\n",
       "      <td>1.743070</td>\n",
       "      <td>34.058344</td>\n",
       "      <td>10.503048</td>\n",
       "      <td>3.910070</td>\n",
       "      <td>1905.701475</td>\n",
       "      <td>0.237276</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>112.766654</td>\n",
       "      <td>49.085352</td>\n",
       "      <td>56.714448</td>\n",
       "      <td>4.880214</td>\n",
       "      <td>10647.951650</td>\n",
       "      <td>11.516657</td>\n",
       "      <td>6.238814</td>\n",
       "      <td>1.512060</td>\n",
       "      <td>0.535067</td>\n",
       "      <td>25.608406</td>\n",
       "      <td>127.591671</td>\n",
       "      <td>19035.709240</td>\n",
       "      <td>36.863947</td>\n",
       "      <td>67.931664</td>\n",
       "      <td>21.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.161666</td>\n",
       "      <td>28688.187660</td>\n",
       "      <td>1910.123198</td>\n",
       "      <td>630.518230</td>\n",
       "      <td>178.943634</td>\n",
       "      <td>38.270880</td>\n",
       "      <td>10.315851</td>\n",
       "      <td>38.971568</td>\n",
       "      <td>1463.693448</td>\n",
       "      <td>53060.599240</td>\n",
       "      <td>29.307300</td>\n",
       "      <td>2447.810550</td>\n",
       "      <td>344.644105</td>\n",
       "      <td>179250.252900</td>\n",
       "      <td>50092.459300</td>\n",
       "      <td>2271.436167</td>\n",
       "      <td>4.103032</td>\n",
       "      <td>633.534408</td>\n",
       "      <td>200.967526</td>\n",
       "      <td>0.224074</td>\n",
       "      <td>31.688153</td>\n",
       "      <td>3.039675</td>\n",
       "      <td>267.942823</td>\n",
       "      <td>4.951507</td>\n",
       "      <td>64.521624</td>\n",
       "      <td>210.330920</td>\n",
       "      <td>2103.405190</td>\n",
       "      <td>37.895013</td>\n",
       "      <td>1.060404</td>\n",
       "      <td>1049.168078</td>\n",
       "      <td>326.236200</td>\n",
       "      <td>62.808096</td>\n",
       "      <td>161.355315</td>\n",
       "      <td>25.192930</td>\n",
       "      <td>152.355164</td>\n",
       "      <td>94.958580</td>\n",
       "      <td>18.324926</td>\n",
       "      <td>30243.758780</td>\n",
       "      <td>42.569748</td>\n",
       "      <td>109.125159</td>\n",
       "      <td>1063.594578</td>\n",
       "      <td>6501.264480</td>\n",
       "      <td>3030.655824</td>\n",
       "      <td>1578.654237</td>\n",
       "      <td>143224.682300</td>\n",
       "      <td>35.851039</td>\n",
       "      <td>137.932739</td>\n",
       "      <td>1244.227020</td>\n",
       "      <td>31.365763</td>\n",
       "      <td>135.781294</td>\n",
       "      <td>1497.351958</td>\n",
       "      <td>143790.071200</td>\n",
       "      <td>81.210825</td>\n",
       "      <td>191.194764</td>\n",
       "      <td>21.978000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AB            AF           AH          AM          AR  \\\n",
       "count  617.000000    617.000000   617.000000  617.000000  617.000000   \n",
       "mean     0.477149   3502.013221   118.624513   38.968552   10.128242   \n",
       "std      0.468388   2300.322717   127.838950   69.728226   10.518877   \n",
       "min      0.081187    192.593280    85.200147    3.177522    8.138688   \n",
       "25%      0.252107   2197.345480    85.200147   12.270314    8.138688   \n",
       "50%      0.354659   3120.318960    85.200147   20.533110    8.138688   \n",
       "75%      0.559763   4361.637390   113.739540   39.139886    8.138688   \n",
       "max      6.161666  28688.187660  1910.123198  630.518230  178.943634   \n",
       "\n",
       "               AX          AY          AZ           BC           BD   \\\n",
       "count  617.000000  617.000000  617.000000   617.000000    617.000000   \n",
       "mean     5.545576    0.060320   10.566447     8.053012   5350.388655   \n",
       "std      2.551696    0.416817    4.350645    65.166943   3021.326641   \n",
       "min      0.699861    0.025578    3.396778     1.229900   1693.624320   \n",
       "25%      4.128294    0.025578    8.129580     1.229900   4155.702870   \n",
       "50%      5.031912    0.025578   10.461320     1.229900   4997.960730   \n",
       "75%      6.431634    0.036845   12.969516     5.081244   6035.885700   \n",
       "max     38.270880   10.315851   38.971568  1463.693448  53060.599240   \n",
       "\n",
       "               BN           BP          BQ             BR            BZ  \\\n",
       "count  617.000000   617.000000  557.000000     617.000000    617.000000   \n",
       "mean    21.419492   231.322223   98.328737    1218.133238    550.632525   \n",
       "std      3.478278   183.992505   96.479371    7575.293707   2076.371275   \n",
       "min      9.886800    72.948951    1.331155      51.216883    257.432377   \n",
       "25%     19.420500   156.847239   27.834425     424.990642    257.432377   \n",
       "50%     21.186000   193.908816   61.642115     627.417402    257.432377   \n",
       "75%     23.657700   247.803462  134.009015     975.649259    257.432377   \n",
       "max     29.307300  2447.810550  344.644105  179250.252900  50092.459300   \n",
       "\n",
       "                CB          CC         CD           CF          CH  \\\n",
       "count   615.000000  614.000000  617.000000  617.000000  617.000000   \n",
       "mean     77.104151    0.688801   90.251735   11.241064    0.030615   \n",
       "std     159.049302    0.263994   51.585130   13.571133    0.014808   \n",
       "min      12.499760    0.176874   23.387600    0.510888    0.003184   \n",
       "25%      23.317567    0.563688   64.724192    5.066306    0.023482   \n",
       "50%      42.554330    0.658715   79.819104    9.123000    0.027860   \n",
       "75%      77.310097    0.772206   99.813520   13.565901    0.034427   \n",
       "max    2271.436167    4.103032  633.534408  200.967526    0.224074   \n",
       "\n",
       "               CL          CR          CS          CU         CW           DA  \\\n",
       "count  617.000000  617.000000  617.000000  617.000000  617.000000  617.000000   \n",
       "mean     1.403761    0.742262   36.917590    1.383792   27.165653   51.128326   \n",
       "std      1.922210    0.281195   17.266347    0.538717   14.645993   21.210888   \n",
       "min      1.050225    0.069225   13.784111    0.137925    7.030640    6.906400   \n",
       "25%      1.050225    0.589575   29.782467    1.070298    7.030640   37.942520   \n",
       "50%      1.050225    0.730800   34.835130    1.351665   36.019104   49.180940   \n",
       "75%      1.228445    0.859350   40.529401    1.660617   37.935832   61.408760   \n",
       "max     31.688153    3.039675  267.942823    4.951507   64.521624  210.330920   \n",
       "\n",
       "                DE          DF          DH           DI          DL  \\\n",
       "count   617.000000  617.000000  617.000000   617.000000  617.000000   \n",
       "mean    401.901299    0.633884    0.367002   146.972099   94.795377   \n",
       "std     317.745623    1.912384    0.112989    86.084419   28.243187   \n",
       "min      35.998895    0.238680    0.040995    60.232470   10.345600   \n",
       "25%     188.815690    0.238680    0.295164   102.703553   78.232240   \n",
       "50%     307.509595    0.238680    0.358023   130.050630   96.264960   \n",
       "75%     507.896200    0.238680    0.426348   165.836955  110.640680   \n",
       "max    2103.405190   37.895013    1.060404  1049.168078  326.236200   \n",
       "\n",
       "               DN          DU          DV          DY          EB          EE  \\\n",
       "count  617.000000  616.000000  617.000000  617.000000  617.000000  617.000000   \n",
       "mean    26.370568    1.802900    1.924830   26.388989    9.072700    3.064778   \n",
       "std      8.038825    9.034721    1.484555   18.116679    6.200281    2.058344   \n",
       "min      6.339496    0.005518    1.743070    0.804068    4.926396    0.286201   \n",
       "25%     20.888264    0.005518    1.743070   14.715792    5.965392    1.648679   \n",
       "50%     25.248800    0.251741    1.743070   21.642456    8.149404    2.616119   \n",
       "75%     30.544224    1.058690    1.743070   34.058344   10.503048    3.910070   \n",
       "max     62.808096  161.355315   25.192930  152.355164   94.958580   18.324926   \n",
       "\n",
       "                 EG          EH          EL           EP           EU  \\\n",
       "count    617.000000  617.000000  557.000000   617.000000   617.000000   \n",
       "mean    1731.248215    0.305107   69.582596   105.060712    69.117005   \n",
       "std     1790.227476    1.847499   38.555707    68.445620   390.187057   \n",
       "min      185.594100    0.003042    5.394675    78.526968     3.828384   \n",
       "25%     1111.160625    0.003042   30.927468    78.526968     4.324656   \n",
       "50%     1493.817413    0.085176   71.949306    78.526968    22.641144   \n",
       "75%     1905.701475    0.237276  109.125159   112.766654    49.085352   \n",
       "max    30243.758780   42.569748  109.125159  1063.594578  6501.264480   \n",
       "\n",
       "                FC          FD              FE          FI          FL  \\\n",
       "count   616.000000   617.000000     617.000000  617.000000  616.000000   \n",
       "mean     71.341526     6.930086   10306.810737   10.111079    5.433199   \n",
       "std     165.551545    64.754262   11331.294051    2.934025   11.496257   \n",
       "min       7.534128     0.296850    1563.136688    3.583450    0.173229   \n",
       "25%      25.815384     0.296850    5164.666260    8.523098    0.173229   \n",
       "50%      36.394008     1.870155    7345.143424    9.945452    3.028141   \n",
       "75%      56.714448     4.880214   10647.951650   11.516657    6.238814   \n",
       "max    3030.655824  1578.654237  143224.682300   35.851039  137.932739   \n",
       "\n",
       "                FR          FS          GB           GE             GF  \\\n",
       "count   617.000000  615.000000  617.000000   617.000000     617.000000   \n",
       "mean      3.533905    0.421501   20.724856   131.714987   14679.595398   \n",
       "std      50.181948    1.305365    9.991907   144.181524   19352.959387   \n",
       "min       0.497060    0.067730    4.102182    72.611063      13.038894   \n",
       "25%       0.497060    0.067730   14.036718    72.611063    2798.992584   \n",
       "50%       1.131000    0.250601   18.771436    72.611063    7838.273610   \n",
       "75%       1.512060    0.535067   25.608406   127.591671   19035.709240   \n",
       "max    1244.227020   31.365763  135.781294  1497.351958  143790.071200   \n",
       "\n",
       "               GH          GI          GL  \n",
       "count  617.000000  617.000000  616.000000  \n",
       "mean    31.489716   50.584437    8.530961  \n",
       "std      9.864239   36.266251   10.327010  \n",
       "min      9.432735    0.897628    0.001129  \n",
       "25%     25.034888   23.011684    0.124392  \n",
       "50%     30.608946   41.007968    0.337827  \n",
       "75%     36.863947   67.931664   21.978000  \n",
       "max     81.210825  191.194764   21.978000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BQ', 'CB', 'CC', 'DU', 'EL', 'FC', 'FL', 'FS', 'GL'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_cols = train_0.columns[train_0.isnull().sum()>0]\n",
    "null_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BQ    60\n",
       "CB     2\n",
       "CC     3\n",
       "DU     1\n",
       "EL    60\n",
       "FC     1\n",
       "FL     1\n",
       "FS     2\n",
       "GL     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_0[null_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_1 = train_0.fillna(train_0.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encore categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "train_1.EJ = encoder.fit_transform(train_1.EJ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(train_1), columns=train_1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Class 1: 0.825\n",
      "Percentage of Class 0: 0.175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    509\n",
       "1    108\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Percentage of Class 1: {(y.value_counts()[0]/y.shape[0]).round(3)}')\n",
    "print(f'Percentage of Class 0: {(y.value_counts()[1]/y.shape[0]).round(3)}')\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def balance_loglossv2(y_true, y_pred):\n",
    "    target_mean = y_true.mean()\n",
    "    w0 = 1/(1-target_mean)\n",
    "    w1 = 1/target_mean\n",
    "    sample_weight = [w0 if y == 0 else w1 for y in y_true]\n",
    "    loss = log_loss(y_true, y_pred, sample_weight=sample_weight)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression score: 0.672\n",
      "Logistic Regression std: 0.067\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr_scores = []\n",
    "\n",
    "# lr_scores.append(cross_val_score(lr, X, y, scoring=log_loss))\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "    \n",
    "    lr_scores.append(balance_loglossv2(y_test, y_pred))\n",
    "    \n",
    "print(f'Logistic Regression score: {np.mean(lr_scores).round(3)}')\n",
    "print(f'Logistic Regression std: {np.std(lr_scores).round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T05:52:12.073600Z",
     "iopub.status.busy": "2023-05-28T05:52:12.073241Z",
     "iopub.status.idle": "2023-05-28T05:52:26.487595Z",
     "shell.execute_reply": "2023-05-28T05:52:26.486517Z",
     "shell.execute_reply.started": "2023-05-28T05:52:12.073572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor score: 0.467\n",
      "Random Forest Regressor std: 0.112\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedKFold(n_splits=5, n_repeats=10, random_state=0)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_scores = []\n",
    "\n",
    "# lr_scores.append(cross_val_score(lr, X, y, scoring=log_loss))\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "    \n",
    "    rf_scores.append(balance_loglossv2(y_test, y_pred))\n",
    "    \n",
    "print(f'Random Forest Regressor score: {np.mean(rf_scores).round(3)}')\n",
    "print(f'Random Forest Regressor std: {np.std(rf_scores).round(3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:18:06.451585Z",
     "iopub.status.busy": "2023-05-28T04:18:06.451214Z",
     "iopub.status.idle": "2023-05-28T04:18:07.653165Z",
     "shell.execute_reply": "2023-05-28T04:18:07.651911Z",
     "shell.execute_reply.started": "2023-05-28T04:18:06.451554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1700e_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1700e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1700e_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_1700e_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1700e_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_1700e_row0_col1\" class=\"data row0 col1\" >3438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1700e_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_1700e_row1_col1\" class=\"data row1 col1\" >Class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1700e_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_1700e_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1700e_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_1700e_row3_col1\" class=\"data row3 col1\" >(617, 57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1700e_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_1700e_row4_col1\" class=\"data row4 col1\" >(617, 57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_1700e_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_1700e_row5_col1\" class=\"data row5 col1\" >(431, 57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_1700e_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_1700e_row6_col1\" class=\"data row6 col1\" >(186, 57)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_1700e_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_1700e_row7_col1\" class=\"data row7 col1\" >56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_1700e_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_1700e_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_1700e_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_1700e_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_1700e_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_1700e_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_1700e_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_1700e_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_1700e_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_1700e_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_1700e_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_1700e_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_1700e_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_1700e_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_1700e_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_1700e_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_1700e_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_1700e_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_1700e_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_1700e_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1700e_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_1700e_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_1700e_row18_col1\" class=\"data row18 col1\" >e5a3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7939f3eb9930>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = setup(data=pd.concat([X, y], axis=1), target='Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:18:07.655236Z",
     "iopub.status.busy": "2023-05-28T04:18:07.654308Z",
     "iopub.status.idle": "2023-05-28T04:18:07.663475Z",
     "shell.execute_reply": "2023-05-28T04:18:07.661781Z",
     "shell.execute_reply.started": "2023-05-28T04:18:07.655214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                              LOG_LOSS\n",
       "Display Name                                      LOG_LOSS\n",
       "Score Function       <function log_loss at 0x793a2827f910>\n",
       "Scorer                               make_scorer(log_loss)\n",
       "Target                                                pred\n",
       "Args                                                    {}\n",
       "Greater is Better                                     True\n",
       "Multiclass                                            True\n",
       "Custom                                                True\n",
       "Name: log_loss, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_metric(id='log_loss', name='LOG_LOSS', score_func=log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:18:07.665194Z",
     "iopub.status.busy": "2023-05-28T04:18:07.664839Z",
     "iopub.status.idle": "2023-05-28T04:19:26.192331Z",
     "shell.execute_reply": "2023-05-28T04:19:26.191164Z",
     "shell.execute_reply.started": "2023-05-28T04:18:07.665163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6e9a6 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6e9a6_row0_col0, #T_6e9a6_row0_col2, #T_6e9a6_row0_col3, #T_6e9a6_row0_col5, #T_6e9a6_row0_col6, #T_6e9a6_row0_col8, #T_6e9a6_row1_col0, #T_6e9a6_row1_col1, #T_6e9a6_row1_col2, #T_6e9a6_row1_col3, #T_6e9a6_row1_col4, #T_6e9a6_row1_col5, #T_6e9a6_row1_col7, #T_6e9a6_row1_col8, #T_6e9a6_row2_col0, #T_6e9a6_row2_col1, #T_6e9a6_row2_col3, #T_6e9a6_row2_col4, #T_6e9a6_row2_col5, #T_6e9a6_row2_col6, #T_6e9a6_row2_col7, #T_6e9a6_row2_col8, #T_6e9a6_row3_col0, #T_6e9a6_row3_col1, #T_6e9a6_row3_col2, #T_6e9a6_row3_col3, #T_6e9a6_row3_col4, #T_6e9a6_row3_col5, #T_6e9a6_row3_col6, #T_6e9a6_row3_col7, #T_6e9a6_row3_col8, #T_6e9a6_row4_col0, #T_6e9a6_row4_col1, #T_6e9a6_row4_col2, #T_6e9a6_row4_col3, #T_6e9a6_row4_col4, #T_6e9a6_row4_col5, #T_6e9a6_row4_col6, #T_6e9a6_row4_col7, #T_6e9a6_row4_col8, #T_6e9a6_row5_col0, #T_6e9a6_row5_col1, #T_6e9a6_row5_col2, #T_6e9a6_row5_col4, #T_6e9a6_row5_col6, #T_6e9a6_row5_col7, #T_6e9a6_row5_col8, #T_6e9a6_row6_col0, #T_6e9a6_row6_col1, #T_6e9a6_row6_col2, #T_6e9a6_row6_col3, #T_6e9a6_row6_col4, #T_6e9a6_row6_col5, #T_6e9a6_row6_col6, #T_6e9a6_row6_col7, #T_6e9a6_row6_col8, #T_6e9a6_row7_col0, #T_6e9a6_row7_col1, #T_6e9a6_row7_col2, #T_6e9a6_row7_col3, #T_6e9a6_row7_col4, #T_6e9a6_row7_col5, #T_6e9a6_row7_col6, #T_6e9a6_row7_col7, #T_6e9a6_row7_col8, #T_6e9a6_row8_col0, #T_6e9a6_row8_col1, #T_6e9a6_row8_col2, #T_6e9a6_row8_col3, #T_6e9a6_row8_col4, #T_6e9a6_row8_col5, #T_6e9a6_row8_col6, #T_6e9a6_row8_col7, #T_6e9a6_row8_col8, #T_6e9a6_row9_col0, #T_6e9a6_row9_col1, #T_6e9a6_row9_col2, #T_6e9a6_row9_col3, #T_6e9a6_row9_col4, #T_6e9a6_row9_col5, #T_6e9a6_row9_col6, #T_6e9a6_row9_col7, #T_6e9a6_row9_col8, #T_6e9a6_row10_col0, #T_6e9a6_row10_col1, #T_6e9a6_row10_col2, #T_6e9a6_row10_col3, #T_6e9a6_row10_col4, #T_6e9a6_row10_col5, #T_6e9a6_row10_col6, #T_6e9a6_row10_col7, #T_6e9a6_row10_col8, #T_6e9a6_row11_col0, #T_6e9a6_row11_col1, #T_6e9a6_row11_col2, #T_6e9a6_row11_col3, #T_6e9a6_row11_col4, #T_6e9a6_row11_col5, #T_6e9a6_row11_col6, #T_6e9a6_row11_col7, #T_6e9a6_row11_col8, #T_6e9a6_row12_col0, #T_6e9a6_row12_col1, #T_6e9a6_row12_col2, #T_6e9a6_row12_col3, #T_6e9a6_row12_col4, #T_6e9a6_row12_col5, #T_6e9a6_row12_col6, #T_6e9a6_row12_col7, #T_6e9a6_row12_col8, #T_6e9a6_row13_col0, #T_6e9a6_row13_col1, #T_6e9a6_row13_col2, #T_6e9a6_row13_col3, #T_6e9a6_row13_col4, #T_6e9a6_row13_col5, #T_6e9a6_row13_col6, #T_6e9a6_row13_col7, #T_6e9a6_row13_col8, #T_6e9a6_row14_col0, #T_6e9a6_row14_col1, #T_6e9a6_row14_col2, #T_6e9a6_row14_col3, #T_6e9a6_row14_col4, #T_6e9a6_row14_col5, #T_6e9a6_row14_col6, #T_6e9a6_row14_col7, #T_6e9a6_row14_col8, #T_6e9a6_row15_col0, #T_6e9a6_row15_col1, #T_6e9a6_row15_col2, #T_6e9a6_row15_col3, #T_6e9a6_row15_col4, #T_6e9a6_row15_col5, #T_6e9a6_row15_col6, #T_6e9a6_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6e9a6_row0_col1, #T_6e9a6_row0_col4, #T_6e9a6_row0_col7, #T_6e9a6_row1_col6, #T_6e9a6_row2_col2, #T_6e9a6_row5_col3, #T_6e9a6_row5_col5, #T_6e9a6_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_6e9a6_row0_col9, #T_6e9a6_row1_col9, #T_6e9a6_row2_col9, #T_6e9a6_row3_col9, #T_6e9a6_row4_col9, #T_6e9a6_row5_col9, #T_6e9a6_row6_col9, #T_6e9a6_row7_col9, #T_6e9a6_row8_col9, #T_6e9a6_row10_col9, #T_6e9a6_row11_col9, #T_6e9a6_row12_col9, #T_6e9a6_row13_col9, #T_6e9a6_row14_col9, #T_6e9a6_row15_col9 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_6e9a6_row9_col9 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6e9a6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e9a6_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6e9a6_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_6e9a6_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_6e9a6_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_6e9a6_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_6e9a6_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_6e9a6_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_6e9a6_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_6e9a6_level0_col8\" class=\"col_heading level0 col8\" >LOG_LOSS</th>\n",
       "      <th id=\"T_6e9a6_level0_col9\" class=\"col_heading level0 col9\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_6e9a6_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_6e9a6_row0_col1\" class=\"data row0 col1\" >0.9234</td>\n",
       "      <td id=\"T_6e9a6_row0_col2\" class=\"data row0 col2\" >0.9570</td>\n",
       "      <td id=\"T_6e9a6_row0_col3\" class=\"data row0 col3\" >0.6196</td>\n",
       "      <td id=\"T_6e9a6_row0_col4\" class=\"data row0 col4\" >0.9405</td>\n",
       "      <td id=\"T_6e9a6_row0_col5\" class=\"data row0 col5\" >0.7137</td>\n",
       "      <td id=\"T_6e9a6_row0_col6\" class=\"data row0 col6\" >0.6774</td>\n",
       "      <td id=\"T_6e9a6_row0_col7\" class=\"data row0 col7\" >0.7102</td>\n",
       "      <td id=\"T_6e9a6_row0_col8\" class=\"data row0 col8\" >2.7604</td>\n",
       "      <td id=\"T_6e9a6_row0_col9\" class=\"data row0 col9\" >0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n",
       "      <td id=\"T_6e9a6_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_6e9a6_row1_col1\" class=\"data row1 col1\" >0.9165</td>\n",
       "      <td id=\"T_6e9a6_row1_col2\" class=\"data row1 col2\" >0.9450</td>\n",
       "      <td id=\"T_6e9a6_row1_col3\" class=\"data row1 col3\" >0.6607</td>\n",
       "      <td id=\"T_6e9a6_row1_col4\" class=\"data row1 col4\" >0.8407</td>\n",
       "      <td id=\"T_6e9a6_row1_col5\" class=\"data row1 col5\" >0.7248</td>\n",
       "      <td id=\"T_6e9a6_row1_col6\" class=\"data row1 col6\" >0.6788</td>\n",
       "      <td id=\"T_6e9a6_row1_col7\" class=\"data row1 col7\" >0.6938</td>\n",
       "      <td id=\"T_6e9a6_row1_col8\" class=\"data row1 col8\" >3.0100</td>\n",
       "      <td id=\"T_6e9a6_row1_col9\" class=\"data row1 col9\" >0.2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row2\" class=\"row_heading level0 row2\" >catboost</th>\n",
       "      <td id=\"T_6e9a6_row2_col0\" class=\"data row2 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_6e9a6_row2_col1\" class=\"data row2 col1\" >0.9164</td>\n",
       "      <td id=\"T_6e9a6_row2_col2\" class=\"data row2 col2\" >0.9704</td>\n",
       "      <td id=\"T_6e9a6_row2_col3\" class=\"data row2 col3\" >0.6071</td>\n",
       "      <td id=\"T_6e9a6_row2_col4\" class=\"data row2 col4\" >0.9092</td>\n",
       "      <td id=\"T_6e9a6_row2_col5\" class=\"data row2 col5\" >0.6904</td>\n",
       "      <td id=\"T_6e9a6_row2_col6\" class=\"data row2 col6\" >0.6505</td>\n",
       "      <td id=\"T_6e9a6_row2_col7\" class=\"data row2 col7\" >0.6844</td>\n",
       "      <td id=\"T_6e9a6_row2_col8\" class=\"data row2 col8\" >3.0138</td>\n",
       "      <td id=\"T_6e9a6_row2_col9\" class=\"data row2 col9\" >5.2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row3\" class=\"row_heading level0 row3\" >lightgbm</th>\n",
       "      <td id=\"T_6e9a6_row3_col0\" class=\"data row3 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_6e9a6_row3_col1\" class=\"data row3 col1\" >0.9142</td>\n",
       "      <td id=\"T_6e9a6_row3_col2\" class=\"data row3 col2\" >0.9616</td>\n",
       "      <td id=\"T_6e9a6_row3_col3\" class=\"data row3 col3\" >0.6607</td>\n",
       "      <td id=\"T_6e9a6_row3_col4\" class=\"data row3 col4\" >0.8092</td>\n",
       "      <td id=\"T_6e9a6_row3_col5\" class=\"data row3 col5\" >0.7081</td>\n",
       "      <td id=\"T_6e9a6_row3_col6\" class=\"data row3 col6\" >0.6627</td>\n",
       "      <td id=\"T_6e9a6_row3_col7\" class=\"data row3 col7\" >0.6769</td>\n",
       "      <td id=\"T_6e9a6_row3_col8\" class=\"data row3 col8\" >3.0938</td>\n",
       "      <td id=\"T_6e9a6_row3_col9\" class=\"data row3 col9\" >0.3710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row4\" class=\"row_heading level0 row4\" >xgboost</th>\n",
       "      <td id=\"T_6e9a6_row4_col0\" class=\"data row4 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_6e9a6_row4_col1\" class=\"data row4 col1\" >0.9119</td>\n",
       "      <td id=\"T_6e9a6_row4_col2\" class=\"data row4 col2\" >0.9593</td>\n",
       "      <td id=\"T_6e9a6_row4_col3\" class=\"data row4 col3\" >0.6518</td>\n",
       "      <td id=\"T_6e9a6_row4_col4\" class=\"data row4 col4\" >0.8108</td>\n",
       "      <td id=\"T_6e9a6_row4_col5\" class=\"data row4 col5\" >0.7078</td>\n",
       "      <td id=\"T_6e9a6_row4_col6\" class=\"data row4 col6\" >0.6595</td>\n",
       "      <td id=\"T_6e9a6_row4_col7\" class=\"data row4 col7\" >0.6729</td>\n",
       "      <td id=\"T_6e9a6_row4_col8\" class=\"data row4 col8\" >3.1757</td>\n",
       "      <td id=\"T_6e9a6_row4_col9\" class=\"data row4 col9\" >0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row5\" class=\"row_heading level0 row5\" >ada</th>\n",
       "      <td id=\"T_6e9a6_row5_col0\" class=\"data row5 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_6e9a6_row5_col1\" class=\"data row5 col1\" >0.9117</td>\n",
       "      <td id=\"T_6e9a6_row5_col2\" class=\"data row5 col2\" >0.9432</td>\n",
       "      <td id=\"T_6e9a6_row5_col3\" class=\"data row5 col3\" >0.6929</td>\n",
       "      <td id=\"T_6e9a6_row5_col4\" class=\"data row5 col4\" >0.7955</td>\n",
       "      <td id=\"T_6e9a6_row5_col5\" class=\"data row5 col5\" >0.7253</td>\n",
       "      <td id=\"T_6e9a6_row5_col6\" class=\"data row5 col6\" >0.6741</td>\n",
       "      <td id=\"T_6e9a6_row5_col7\" class=\"data row5 col7\" >0.6854</td>\n",
       "      <td id=\"T_6e9a6_row5_col8\" class=\"data row5 col8\" >3.1814</td>\n",
       "      <td id=\"T_6e9a6_row5_col9\" class=\"data row5 col9\" >0.1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row6\" class=\"row_heading level0 row6\" >et</th>\n",
       "      <td id=\"T_6e9a6_row6_col0\" class=\"data row6 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_6e9a6_row6_col1\" class=\"data row6 col1\" >0.9002</td>\n",
       "      <td id=\"T_6e9a6_row6_col2\" class=\"data row6 col2\" >0.9631</td>\n",
       "      <td id=\"T_6e9a6_row6_col3\" class=\"data row6 col3\" >0.4857</td>\n",
       "      <td id=\"T_6e9a6_row6_col4\" class=\"data row6 col4\" >0.9300</td>\n",
       "      <td id=\"T_6e9a6_row6_col5\" class=\"data row6 col5\" >0.6024</td>\n",
       "      <td id=\"T_6e9a6_row6_col6\" class=\"data row6 col6\" >0.5583</td>\n",
       "      <td id=\"T_6e9a6_row6_col7\" class=\"data row6 col7\" >0.6102</td>\n",
       "      <td id=\"T_6e9a6_row6_col8\" class=\"data row6 col8\" >3.5967</td>\n",
       "      <td id=\"T_6e9a6_row6_col9\" class=\"data row6 col9\" >0.2440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row7\" class=\"row_heading level0 row7\" >ridge</th>\n",
       "      <td id=\"T_6e9a6_row7_col0\" class=\"data row7 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_6e9a6_row7_col1\" class=\"data row7 col1\" >0.8910</td>\n",
       "      <td id=\"T_6e9a6_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_6e9a6_row7_col3\" class=\"data row7 col3\" >0.4589</td>\n",
       "      <td id=\"T_6e9a6_row7_col4\" class=\"data row7 col4\" >0.8348</td>\n",
       "      <td id=\"T_6e9a6_row7_col5\" class=\"data row7 col5\" >0.5714</td>\n",
       "      <td id=\"T_6e9a6_row7_col6\" class=\"data row7 col6\" >0.5217</td>\n",
       "      <td id=\"T_6e9a6_row7_col7\" class=\"data row7 col7\" >0.5599</td>\n",
       "      <td id=\"T_6e9a6_row7_col8\" class=\"data row7 col8\" >3.9301</td>\n",
       "      <td id=\"T_6e9a6_row7_col9\" class=\"data row7 col9\" >0.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row8\" class=\"row_heading level0 row8\" >lda</th>\n",
       "      <td id=\"T_6e9a6_row8_col0\" class=\"data row8 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_6e9a6_row8_col1\" class=\"data row8 col1\" >0.8886</td>\n",
       "      <td id=\"T_6e9a6_row8_col2\" class=\"data row8 col2\" >0.9147</td>\n",
       "      <td id=\"T_6e9a6_row8_col3\" class=\"data row8 col3\" >0.5732</td>\n",
       "      <td id=\"T_6e9a6_row8_col4\" class=\"data row8 col4\" >0.7379</td>\n",
       "      <td id=\"T_6e9a6_row8_col5\" class=\"data row8 col5\" >0.6391</td>\n",
       "      <td id=\"T_6e9a6_row8_col6\" class=\"data row8 col6\" >0.5750</td>\n",
       "      <td id=\"T_6e9a6_row8_col7\" class=\"data row8 col7\" >0.5849</td>\n",
       "      <td id=\"T_6e9a6_row8_col8\" class=\"data row8 col8\" >4.0140</td>\n",
       "      <td id=\"T_6e9a6_row8_col9\" class=\"data row8 col9\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row9\" class=\"row_heading level0 row9\" >svm</th>\n",
       "      <td id=\"T_6e9a6_row9_col0\" class=\"data row9 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_6e9a6_row9_col1\" class=\"data row9 col1\" >0.8863</td>\n",
       "      <td id=\"T_6e9a6_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_6e9a6_row9_col3\" class=\"data row9 col3\" >0.5589</td>\n",
       "      <td id=\"T_6e9a6_row9_col4\" class=\"data row9 col4\" >0.7687</td>\n",
       "      <td id=\"T_6e9a6_row9_col5\" class=\"data row9 col5\" >0.5989</td>\n",
       "      <td id=\"T_6e9a6_row9_col6\" class=\"data row9 col6\" >0.5418</td>\n",
       "      <td id=\"T_6e9a6_row9_col7\" class=\"data row9 col7\" >0.5750</td>\n",
       "      <td id=\"T_6e9a6_row9_col8\" class=\"data row9 col8\" >4.0978</td>\n",
       "      <td id=\"T_6e9a6_row9_col9\" class=\"data row9 col9\" >0.0270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row10\" class=\"row_heading level0 row10\" >lr</th>\n",
       "      <td id=\"T_6e9a6_row10_col0\" class=\"data row10 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_6e9a6_row10_col1\" class=\"data row10 col1\" >0.8655</td>\n",
       "      <td id=\"T_6e9a6_row10_col2\" class=\"data row10 col2\" >0.9013</td>\n",
       "      <td id=\"T_6e9a6_row10_col3\" class=\"data row10 col3\" >0.2964</td>\n",
       "      <td id=\"T_6e9a6_row10_col4\" class=\"data row10 col4\" >0.8417</td>\n",
       "      <td id=\"T_6e9a6_row10_col5\" class=\"data row10 col5\" >0.4218</td>\n",
       "      <td id=\"T_6e9a6_row10_col6\" class=\"data row10 col6\" >0.3688</td>\n",
       "      <td id=\"T_6e9a6_row10_col7\" class=\"data row10 col7\" >0.4369</td>\n",
       "      <td id=\"T_6e9a6_row10_col8\" class=\"data row10 col8\" >4.8465</td>\n",
       "      <td id=\"T_6e9a6_row10_col9\" class=\"data row10 col9\" >0.2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row11\" class=\"row_heading level0 row11\" >qda</th>\n",
       "      <td id=\"T_6e9a6_row11_col0\" class=\"data row11 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_6e9a6_row11_col1\" class=\"data row11 col1\" >0.8492</td>\n",
       "      <td id=\"T_6e9a6_row11_col2\" class=\"data row11 col2\" >0.6937</td>\n",
       "      <td id=\"T_6e9a6_row11_col3\" class=\"data row11 col3\" >0.1750</td>\n",
       "      <td id=\"T_6e9a6_row11_col4\" class=\"data row11 col4\" >0.6333</td>\n",
       "      <td id=\"T_6e9a6_row11_col5\" class=\"data row11 col5\" >0.2644</td>\n",
       "      <td id=\"T_6e9a6_row11_col6\" class=\"data row11 col6\" >0.2266</td>\n",
       "      <td id=\"T_6e9a6_row11_col7\" class=\"data row11 col7\" >0.2871</td>\n",
       "      <td id=\"T_6e9a6_row11_col8\" class=\"data row11 col8\" >5.4351</td>\n",
       "      <td id=\"T_6e9a6_row11_col9\" class=\"data row11 col9\" >0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_6e9a6_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_6e9a6_row12_col1\" class=\"data row12 col1\" >0.8468</td>\n",
       "      <td id=\"T_6e9a6_row12_col2\" class=\"data row12 col2\" >0.7992</td>\n",
       "      <td id=\"T_6e9a6_row12_col3\" class=\"data row12 col3\" >0.2411</td>\n",
       "      <td id=\"T_6e9a6_row12_col4\" class=\"data row12 col4\" >0.6500</td>\n",
       "      <td id=\"T_6e9a6_row12_col5\" class=\"data row12 col5\" >0.3422</td>\n",
       "      <td id=\"T_6e9a6_row12_col6\" class=\"data row12 col6\" >0.2812</td>\n",
       "      <td id=\"T_6e9a6_row12_col7\" class=\"data row12 col7\" >0.3264</td>\n",
       "      <td id=\"T_6e9a6_row12_col8\" class=\"data row12 col8\" >5.5209</td>\n",
       "      <td id=\"T_6e9a6_row12_col9\" class=\"data row12 col9\" >0.0420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row13\" class=\"row_heading level0 row13\" >nb</th>\n",
       "      <td id=\"T_6e9a6_row13_col0\" class=\"data row13 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_6e9a6_row13_col1\" class=\"data row13 col1\" >0.8399</td>\n",
       "      <td id=\"T_6e9a6_row13_col2\" class=\"data row13 col2\" >0.8413</td>\n",
       "      <td id=\"T_6e9a6_row13_col3\" class=\"data row13 col3\" >0.3625</td>\n",
       "      <td id=\"T_6e9a6_row13_col4\" class=\"data row13 col4\" >0.5305</td>\n",
       "      <td id=\"T_6e9a6_row13_col5\" class=\"data row13 col5\" >0.4115</td>\n",
       "      <td id=\"T_6e9a6_row13_col6\" class=\"data row13 col6\" >0.3303</td>\n",
       "      <td id=\"T_6e9a6_row13_col7\" class=\"data row13 col7\" >0.3458</td>\n",
       "      <td id=\"T_6e9a6_row13_col8\" class=\"data row13 col8\" >5.7704</td>\n",
       "      <td id=\"T_6e9a6_row13_col9\" class=\"data row13 col9\" >0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row14\" class=\"row_heading level0 row14\" >dt</th>\n",
       "      <td id=\"T_6e9a6_row14_col0\" class=\"data row14 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_6e9a6_row14_col1\" class=\"data row14 col1\" >0.8353</td>\n",
       "      <td id=\"T_6e9a6_row14_col2\" class=\"data row14 col2\" >0.7354</td>\n",
       "      <td id=\"T_6e9a6_row14_col3\" class=\"data row14 col3\" >0.5804</td>\n",
       "      <td id=\"T_6e9a6_row14_col4\" class=\"data row14 col4\" >0.5338</td>\n",
       "      <td id=\"T_6e9a6_row14_col5\" class=\"data row14 col5\" >0.5451</td>\n",
       "      <td id=\"T_6e9a6_row14_col6\" class=\"data row14 col6\" >0.4469</td>\n",
       "      <td id=\"T_6e9a6_row14_col7\" class=\"data row14 col7\" >0.4542</td>\n",
       "      <td id=\"T_6e9a6_row14_col8\" class=\"data row14 col8\" >5.9381</td>\n",
       "      <td id=\"T_6e9a6_row14_col9\" class=\"data row14 col9\" >0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e9a6_level0_row15\" class=\"row_heading level0 row15\" >dummy</th>\n",
       "      <td id=\"T_6e9a6_row15_col0\" class=\"data row15 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_6e9a6_row15_col1\" class=\"data row15 col1\" >0.8260</td>\n",
       "      <td id=\"T_6e9a6_row15_col2\" class=\"data row15 col2\" >0.5000</td>\n",
       "      <td id=\"T_6e9a6_row15_col3\" class=\"data row15 col3\" >0.0000</td>\n",
       "      <td id=\"T_6e9a6_row15_col4\" class=\"data row15 col4\" >0.0000</td>\n",
       "      <td id=\"T_6e9a6_row15_col5\" class=\"data row15 col5\" >0.0000</td>\n",
       "      <td id=\"T_6e9a6_row15_col6\" class=\"data row15 col6\" >0.0000</td>\n",
       "      <td id=\"T_6e9a6_row15_col7\" class=\"data row15 col7\" >0.0000</td>\n",
       "      <td id=\"T_6e9a6_row15_col8\" class=\"data row15 col8\" >6.2714</td>\n",
       "      <td id=\"T_6e9a6_row15_col9\" class=\"data row15 col9\" >0.0860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x793a00205f30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.194371Z",
     "iopub.status.busy": "2023-05-28T04:19:26.193679Z",
     "iopub.status.idle": "2023-05-28T04:19:26.206225Z",
     "shell.execute_reply": "2023-05-28T04:19:26.205141Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.194321Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def lightgbm(trial):\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'metric': 'binary_logloss',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 100),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-9, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-9, 10.0),\n",
    "        'random_state': 0\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**params)\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "        results.append(balance_loglossv2(y_test, y_pred))\n",
    "            \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.208196Z",
     "iopub.status.busy": "2023-05-28T04:19:26.207831Z",
     "iopub.status.idle": "2023-05-28T04:19:26.223301Z",
     "shell.execute_reply": "2023-05-28T04:19:26.222454Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.208166Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.1, 1),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.1, 1),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-10, 1),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-10, 1),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-10, 1),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'random_state': 0,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**params)\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "        results.append(balance_loglossv2(y_test, y_pred))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.226329Z",
     "iopub.status.busy": "2023-05-28T04:19:26.224756Z",
     "iopub.status.idle": "2023-05-28T04:19:26.242588Z",
     "shell.execute_reply": "2023-05-28T04:19:26.241580Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.226282Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def catboost(trial):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 1, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 0.1, 10.0),\n",
    "        'random_seed': 0,\n",
    "        'loss_function': 'MultiClass',\n",
    "        'eval_metric': 'MultiClass',\n",
    "        'verbose': False\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_test, y_test), early_stopping_rounds=50, verbose=False)\n",
    "        y_pred = model.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "        results.append(balance_loglossv2(y_test, y_pred))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.246266Z",
     "iopub.status.busy": "2023-05-28T04:19:26.245954Z",
     "iopub.status.idle": "2023-05-28T04:19:26.260037Z",
     "shell.execute_reply": "2023-05-28T04:19:26.259184Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.246233Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def rf(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 100)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 100)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 100)\n",
    "    random_state = 0\n",
    "          \n",
    "    model = RandomForestClassifier(\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_samples_split=min_samples_split,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "        results.append(balance_loglossv2(y_test, y_pred))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.262673Z",
     "iopub.status.busy": "2023-05-28T04:19:26.261487Z",
     "iopub.status.idle": "2023-05-28T04:19:26.275155Z",
     "shell.execute_reply": "2023-05-28T04:19:26.273871Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.262563Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def gbc(trial):\n",
    "    #tol = trial.suggest_loguniform('tol', 1e-8, 10.0)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 50)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', .001, 1)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 500)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 100)\n",
    "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 2, 100)\n",
    "    random_state = 0\n",
    "          \n",
    "    model = GradientBoostingClassifier(\n",
    "        #tol=tol,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "        results.append(balance_loglossv2(y_test, y_pred))\n",
    "    \n",
    "    return np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.276623Z",
     "iopub.status.busy": "2023-05-28T04:19:26.276295Z",
     "iopub.status.idle": "2023-05-28T04:19:26.292590Z",
     "shell.execute_reply": "2023-05-28T04:19:26.291213Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.276590Z"
    }
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='minimize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(lightgbm, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.294368Z",
     "iopub.status.busy": "2023-05-28T04:19:26.293993Z",
     "iopub.status.idle": "2023-05-28T04:19:26.305791Z",
     "shell.execute_reply": "2023-05-28T04:19:26.304331Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.294335Z"
    }
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='minimize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(xgb, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.308198Z",
     "iopub.status.busy": "2023-05-28T04:19:26.307421Z",
     "iopub.status.idle": "2023-05-28T04:19:26.317963Z",
     "shell.execute_reply": "2023-05-28T04:19:26.316683Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.308160Z"
    }
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='minimize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(catboost, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.324239Z",
     "iopub.status.busy": "2023-05-28T04:19:26.323882Z",
     "iopub.status.idle": "2023-05-28T04:19:26.330252Z",
     "shell.execute_reply": "2023-05-28T04:19:26.329377Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.324215Z"
    }
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='minimize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(rf, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T04:19:26.331893Z",
     "iopub.status.busy": "2023-05-28T04:19:26.331564Z",
     "iopub.status.idle": "2023-05-28T04:19:26.341857Z",
     "shell.execute_reply": "2023-05-28T04:19:26.340954Z",
     "shell.execute_reply.started": "2023-05-28T04:19:26.331865Z"
    }
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='minimize')\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study.optimize(gbc, n_trials=100)\n",
    "# study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lightgbm_params = {\n",
    "    'n_estimators': 381,\n",
    "    'max_depth': 41,\n",
    "    'num_leaves': 40,\n",
    "    'learning_rate': 0.04226293637542078,\n",
    "    'min_child_samples': 85,\n",
    "    'subsample': 0.3840208956748839,\n",
    "    'colsample_bytree': 0.2175935372225782,\n",
    "    'reg_alpha': 1.441590199129099e-09,\n",
    "    'reg_lambda': 3.2224838933410242e-09,\n",
    "    'force_col_wise': True,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 821,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.01677173900768991,\n",
    "    'subsample': 0.8572143331039203,\n",
    "    'colsample_bytree': 0.5665388026502962,\n",
    "    'reg_alpha': 3.409425580142812e-10,\n",
    "    'reg_lambda': 7.315443625060416e-05,\n",
    "    'gamma': 0.12097663988470606,\n",
    "    'min_child_weight': 4\n",
    "}\n",
    "catboost_params = {\n",
    "    'iterations': 407,\n",
    "    'depth': 3,\n",
    "    'learning_rate': 0.08469439310905212,\n",
    "    'l2_leaf_reg': 2.7207891695705144,\n",
    "    'logging_level': 'Silent'\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'max_depth': 63,\n",
    "    'n_estimators': 221,\n",
    "    'min_samples_leaf': 3,\n",
    "    'min_samples_split': 7\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "gbc_params = {\n",
    "    'max_depth': 30,\n",
    "    'learning_rate': 0.1344660323554811,\n",
    "    'n_estimators': 102,\n",
    "    'min_samples_leaf': 69,\n",
    "    'max_leaf_nodes': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lightgbm_model = LGBMClassifier(**lightgbm_params)\n",
    "xgb_model = XGBClassifier(**xgb_params)\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "cat_model = CatBoostClassifier(**catboost_params)\n",
    "gbc_model = GradientBoostingClassifier(**gbc_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'lightgbm': lightgbm_model,\n",
    "    'xgb': xgb_model,\n",
    "    'rf': rf_model,\n",
    "    'cat': cat_model,\n",
    "    'gbc': gbc_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T05:52:26.566065Z",
     "iopub.status.busy": "2023-05-28T05:52:26.565091Z",
     "iopub.status.idle": "2023-05-28T05:55:24.032899Z",
     "shell.execute_reply": "2023-05-28T05:55:24.031980Z",
     "shell.execute_reply.started": "2023-05-28T05:52:26.565951Z"
    }
   },
   "outputs": [],
   "source": [
    "results_ensemble_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    res=[]\n",
    "    for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "        res.append(balance_loglossv2(y_test, y_pred))\n",
    "    results_ensemble_models[name] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T05:55:24.035706Z",
     "iopub.status.busy": "2023-05-28T05:55:24.035356Z",
     "iopub.status.idle": "2023-05-28T05:55:24.041927Z",
     "shell.execute_reply": "2023-05-28T05:55:24.040920Z",
     "shell.execute_reply.started": "2023-05-28T05:55:24.035678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "lightgbm\n",
      "0.4237760457903404\n",
      "0.10712851794883253\n",
      "----------\n",
      "xgb\n",
      "0.38216076661375675\n",
      "0.07730683549758163\n",
      "----------\n",
      "rf\n",
      "0.46855853961504146\n",
      "0.05454695090186046\n",
      "----------\n",
      "cat\n",
      "0.46047316401882765\n",
      "0.12849492944444155\n",
      "----------\n",
      "gbc\n",
      "0.37380119365573977\n",
      "0.09936713902656993\n"
     ]
    }
   ],
   "source": [
    "for name, result in results_ensemble_models.items():\n",
    "    print(\"----------\\n\" + name)\n",
    "    print(np.mean(result))\n",
    "    print(np.std(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:30] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:31] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:31] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:32] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:33] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:34] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:34] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:35] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:36] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:36] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:37] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:38] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:38] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:39] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:40] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:40] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:41] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:42] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:42] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:43] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:44] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:45] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:45] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:46] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:47] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:48] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:48] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:49] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:50] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:50] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:51] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:52] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:52] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:53] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:54] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:54] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:55] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:56] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:57] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:57] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:58] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:59] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:59] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:00] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:01] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:01] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:02] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:03] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:03] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:04] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.3691772664071108\n"
     ]
    }
   ],
   "source": [
    "final_model = VotingClassifier(estimators=[('xgb', xgb_model),\n",
    "                                           ('gbc', gbc_model)], \n",
    "                               voting='soft')\n",
    "\n",
    "results_ensemble = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_pred = final_model.predict_proba(X_test)\n",
    "    y_pred = final_model.predict_proba(X_test)[:, 1].reshape(-1)\n",
    "    results_ensemble.append(balance_loglossv2(y_test, y_pred))\n",
    "\n",
    "print(np.mean(results_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:15:05] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anes3\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.5665388026502962,\n",
       "                                            enable_categorical=False,\n",
       "                                            gamma=0.12097663988470606,\n",
       "                                            gpu_id=None, importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=0.01677173900768991,\n",
       "                                            max_delta_step=None, max_depth=10,\n",
       "                                            min_child_...\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=3.409425580142812e-10,\n",
       "                                            reg_lambda=7.315443625060416e-05,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=0.8572143331039203,\n",
       "                                            tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                             ('gbc',\n",
       "                              GradientBoostingClassifier(learning_rate=0.1344660323554811,\n",
       "                                                         max_depth=30,\n",
       "                                                         max_leaf_nodes=9,\n",
       "                                                         min_samples_leaf=69,\n",
       "                                                         n_estimators=102))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_final = test.drop('Id', axis=1).copy()\n",
    "test_final.EJ = encoder.transform(test_final.EJ)\n",
    "\n",
    "test_final = pd.DataFrame(scaler.transform(test_final), columns=test_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_0</th>\n",
       "      <th>class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00eed32682bb</td>\n",
       "      <td>0.667246</td>\n",
       "      <td>0.332754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>010ebe33f668</td>\n",
       "      <td>0.667246</td>\n",
       "      <td>0.332754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02fa521e1838</td>\n",
       "      <td>0.667246</td>\n",
       "      <td>0.332754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>040e15f562a2</td>\n",
       "      <td>0.667246</td>\n",
       "      <td>0.332754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>046e85c7cc7f</td>\n",
       "      <td>0.667246</td>\n",
       "      <td>0.332754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   class_0   class_1\n",
       "0  00eed32682bb  0.667246  0.332754\n",
       "1  010ebe33f668  0.667246  0.332754\n",
       "2  02fa521e1838  0.667246  0.332754\n",
       "3  040e15f562a2  0.667246  0.332754\n",
       "4  046e85c7cc7f  0.667246  0.332754"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions = pd.DataFrame(final_model.predict_proba(test_final), columns=['class_0', 'class_1'])\n",
    "final_predictions = pd.concat([test.Id, final_predictions], axis=1)\n",
    "final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_predictions.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
